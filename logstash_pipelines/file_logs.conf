input {
  file {
    mode => "tail"
    path => "/usr/share/logstash/ingest_data/*"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
    # grok {
    #         match => { "message" => "%{SYSLOG5424PRI}%{NONNEGINT:ver} +(?:%{TIMESTAMP_ISO8601:ts}|-) +(?:%{HOSTNAME:service}|-) +(?:%{NOTSPACE:containerName}|-) +(?:%{NOTSPACE:proc}|-) +(?:%{WORD:msgid}|-) +(?:%{SYSLOG5424SD:sd}|-|) +%{GREEDYDATA:msg}" }
    #   }
    #   syslog_pri { }
    #   date {
    #         match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    #   }
    #   mutate {
    #         remove_field => [ "message", "priority", "ts", "severity", "facility", "facility_label", "severity_label", "syslog5424_pri", "proc", "syslog_severity_code", "syslog_facility_code", "syslog_facility", "syslog_severity", "syslog_hostname", "syslog_message", "syslog_timestamp", "ver" ]
    #   }
    #   mutate {
    #         remove_tag => [ "_grokparsefailure_sysloginput" ]
    #   }
    #   mutate {
    #         gsub => [
    #               "service", "[0123456789-]", ""
    #         ]
    #   }
    #   if [msg] =~ "^ *{" {
    #         json {
    #               source => "msg"
    #         }
    #         if "_jsonparsefailure" in [tags] {
    #               drop {}
    #         }
    #         mutate {
    #               remove_field => [ "msg" ]
    #         }
    #   }
  }

output {
  stdout {}
  elasticsearch {
    hosts => ["https://es01:9200"]
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
    cacert => ["certificates/ca/ca.crt"]
    index => "docker-logs-%{+YYYY.MM.dd}"
  }
}
