input {
  file {
    mode => "tail"
    path => "/docker_network_logs/*/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "plain"
    tags => ["docker-daemon"]
  }
}

filter {
  # Extract fields from the message using Grok
  grok {
    match => {
      "message" => [
        # Format 1: Structured IPC log with JSON payload
        "\[%{TIMESTAMP_ISO8601:timestamp}\]\[%{DATA:component}\] \(%{DATA:thread_id}\) %{DATA:session_id} %{DATA:direction} %{DATA:request} \(%{NUMBER:latency_ms:float}ms\): %{GREEDYDATA:json_message}",

        # Format 2: IPC log without JSON
        "\[%{TIMESTAMP_ISO8601:timestamp}\]\[%{DATA:component}\] \(%{DATA:thread_id}\) %{DATA:session_id} %{DATA:direction} %{DATA:request} %{WORD:http_method} %{URI:request_path} \(%{NUMBER:latency_s:float}s\)",

        # Format 3: Docker Hub HTTP request
        "\[%{TIMESTAMP_ISO8601:timestamp}\] req %{NUMBER:req_id} HTTP %{WORD:http_method} %{URI:http_url}: %{WORD:status} with %{NUMBER:bytes_transferred:int} bytes transferred \(%{NUMBER:remaining_http:int} remaining in-progress HTTP requests\)",

        # Format 4: Network dial
        "\[%{TIMESTAMP_ISO8601:timestamp}\]\[%{DATA:component}\] %{IP:remote_ip}:%{NUMBER:remote_port} <- %{IP:local_ip}:%{NUMBER:local_port}: %{GREEDYDATA:connection_status}"

        # Format 5: Get container stats
        "\[%{TIMESTAMP_ISO8601:timestamp}\]\[%{DATA:component}\] >> %{WORD:method} %{URIPATH:request_path}"

        # Format 6: Container stats response
        "\[%{TIMESTAMP_ISO8601:timestamp}\]\[%{DATA:component}\] \(%{DATA:session_id}\) %{DATA:request_name} %{DATA:direction} %{DATA:category} %{WORD:method} %{URIPATH:request_path}"
      ]
    }
  }

  # Parse the timestamp and convert it to @timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
    remove_field => ["timestamp"]  # Remove the original timestamp field if needed
  }

  # Optional: Parse JSON from the json_message field
  json {
    source => "json_message"
    target => "json_parsed"  # Store the parsed JSON in a new field
    remove_field => ["json_message"]  # Optional: Remove the raw JSON string after parsing
  }

  # Rename JSON fields to make them more readable
  mutate {
    rename => {
      "[json_parsed][cpuPercentage]" => "cpu_percentage"
      "[json_parsed][memAvailableBytes]" => "mem_available_bytes"
      "[json_parsed][memBytes]" => "mem_bytes"
      "[json_parsed][numCPU]" => "num_cpu"
    }
  }

  # Optional: Rename other fields as necessary
  mutate {
    rename => {
      "req_id" => "request_id"
      "http_method" => "method"
      "http_url" => "url"
      "bytes_transferred" => "bytes"
      "remaining_http" => "remaining_requests"
      "remote_ip" => "remote_ip_address"
      "local_ip" => "local_ip_address"
      "connection_status" => "status"
    }
  }
}



output {
  stdout {}
  elasticsearch {
    hosts => ["https://es01:9200"]
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
    cacert => ["certificates/ca/ca.crt"]
    index => "docker-deamon-logs-%{+YYYY.MM.dd}"
  }
}
